<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Class 9: Taylor's Theorem and the Second Derivative Test</title>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #e74c3c;
            --background-color: #f9f9f9;
            --text-color: #333;
            --container-shadow: 0 10px 30px rgba(0, 0, 0, 0.08);
            --text-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }

        body {
            font-family: 'Georgia', serif;
            line-height: 1.7;
            margin: 0;
            padding: 0;
            background-color: var(--background-color);
            color: var(--text-color);
        }

        .container {
            max-width: 900px;
            margin: 20px auto;
            padding: 30px;
            background-color: white;
            box-shadow: var(--container-shadow);
            border-radius: 15px;
        }

        header {
            text-align: center;
            margin-bottom: 40px;
            border-bottom: 2px solid var(--secondary-color);
            padding-bottom: 20px;
        }

        h1, h2, h3 {
            color: var(--primary-color);
        }

        .section-title {
            color: var(--primary-color);
            font-size: 1.8rem;
            margin-top: 30px;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 1px solid #eee;
            text-shadow: var(--text-shadow);
        }

        .lecture-title {
            color: var(--secondary-color);
            font-size: 1.5rem;
            margin-bottom: 15px;
            font-weight: normal;
        }

        .author-info {
            font-style: italic;
            color: #777;
        }

        .math {
            font-style: italic;
            padding: 0 3px;
        }

        .figure {
            text-align: center;
            margin: 30px 0;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.05);
        }

        .figure img {
            max-width: 100%;
            border-radius: 5px;
        }

        .figure-caption {
            font-style: italic;
            color: #777;
            margin-top: 15px;
        }

        .navigation {
            margin-top: 40px;
            text-align: center;
            display: flex;
            justify-content: space-between;
            padding: 15px 0;
            border-top: 1px solid #eee;
        }

        .navigation a {
            display: inline-block;
            padding: 10px 20px;
            background-color: var(--primary-color);
            color: white;
            text-decoration: none;
            border-radius: 8px;
            transition: all 0.3s ease;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .navigation a:hover {
            background-color: var(--secondary-color);
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
        }

        .topic-highlight {
            display: inline-block;
            background-color: rgba(52, 152, 219, 0.1);
            padding: 2px 8px;
            border-radius: 4px;
            font-weight: 500;
            color: var(--primary-color);
        }

        .formula {
            margin: 25px 0;
            padding: 15px;
            background-color: #f8f9fa;
            border-left: 4px solid var(--secondary-color);
            border-radius: 5px;
            overflow-x: auto;
            font-size: 1.1em;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
        }

        .example-title {
            font-weight: bold;
            font-size: 1.2em;
            color: var(--secondary-color);
            margin-top: 30px;
            margin-bottom: 15px;
            padding-bottom: 5px;
            border-bottom: 1px dashed #ccc;
            display: inline-block;
        }

        p {
            margin-bottom: 20px;
            line-height: 1.8;
        }

        .content-section {
            padding-bottom: 30px;
        }
        
        .footnote {
            font-size: 0.9em;
            color: #777;
            margin-top: 5px;
            border-top: 1px solid #eee;
            padding-top: 10px;
        }
    </style>
    <!-- MathJax configuration -->
    <script>
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$']],
          displayMath: [['$$', '$$']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
</head>
<body>
    <div class="container">
        <header>
            <h1>Differential and Integral Calculus I</h1>
            <div class="lecture-title">Engineering: Electrical & Electronic Group 4</div>
            <div class="author-info">Lecture Notes</div>
        </header>
        
        <section id="class9" class="content-section">
            <div class="section-title">Class 9: Taylor's Theorem and the Second Derivative Test</div>

            <p>In previous classes, we learned how to find critical points of a function by locating where the gradient vanishes. Today, we'll develop a systematic way to classify these critical points as maxima, minima, or saddle points using <span class="topic-highlight">Taylor expansion</span> and the <span class="topic-highlight">second derivative test</span>.</p>

            <p>Let's begin by recalling the one-dimensional Taylor expansion. For a function $f(x)$ around a point $a$, we have:</p>
            
            <div class="formula">
                $$f(x) = f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \frac{f'''(a)}{3!}(x-a)^3 + \cdots$$
            </div>
            
            <p>This representation approximates the function by a polynomial whose coefficients depend on the function's derivatives. For multivariable functions, the concept extends naturally, but the notation gets more involved.</p>

            <p>Consider a function $f(x,y)$ and a point $(a,b)$ where we want to analyze the behavior. If $(a,b)$ is a critical point, we know that $\nabla f(a,b) = \mathbf{0}$, meaning $f_x(a,b) = f_y(a,b) = 0$. The multivariable Taylor expansion around $(a,b)$ takes the form:</p>
            
            <div class="formula">
                \begin{align}
                f(x,y) &= f(a,b) + \Big[f_x(a,b)(x-a) + f_y(a,b)(y-b)\Big] \\
                &+ \frac{1}{2!}\Big[f_{xx}(a,b)(x-a)^2 + 2f_{xy}(a,b)(x-a)(y-b) + f_{yy}(a,b)(y-b)^2\Big] \\
                &+ \text{(higher order terms)}
                \end{align}
            </div>
            
            <p>At a critical point, the first-order terms vanish because $f_x(a,b) = f_y(a,b) = 0$. So the behavior of the function near the critical point is determined primarily by the second-order terms:</p>
            
            <div class="formula">
                $$f(x,y) \approx f(a,b) + \frac{1}{2}\Big[f_{xx}(a,b)(x-a)^2 + 2f_{xy}(a,b)(x-a)(y-b) + f_{yy}(a,b)(y-b)^2\Big]$$
            </div>

            <p>This quadratic expression gives us insight into the function's behavior near the critical point. We can rewrite this using matrix notation. Let's define:</p>
            
            <div class="formula">
                $$H = \begin{pmatrix} f_{xx}(a,b) & f_{xy}(a,b) \\ f_{xy}(a,b) & f_{yy}(a,b) \end{pmatrix}$$
            </div>
            
            <p>This matrix $H$ is called the <span class="topic-highlight">Hessian matrix</span> at the point $(a,b)$. Using vector notation $\mathbf{v} = (x-a, y-b)^T$, we can rewrite our approximation as:</p>
            
            <div class="formula">
                $$f(x,y) \approx f(a,b) + \frac{1}{2}\mathbf{v}^T H \mathbf{v}$$
            </div>
            
            <p>The behavior of this quadratic form is determined by the eigenvalues of the Hessian matrix $H$. Three cases arise:</p>
            
            <div class="figure" style="background-color: #eefaf8; border-left: 4px solid #2ecc71; text-align: left;">
                <h3 style="margin-top: 0;">Classification of Critical Points</h3>
                <ul style="padding-left: 20px;">
                    <li><strong>Local Minimum:</strong> If all eigenvalues of $H$ are positive (H is positive definite), then $(a,b)$ is a local minimum.</li>
                    <li><strong>Local Maximum:</strong> If all eigenvalues of $H$ are negative (H is negative definite), then $(a,b)$ is a local maximum.</li>
                    <li><strong>Saddle Point:</strong> If $H$ has both positive and negative eigenvalues (H is indefinite), then $(a,b)$ is a saddle point.</li>
                    <li><strong>Degenerate Case:</strong> If any eigenvalue of $H$ is zero, higher-order terms are needed for classification.</li>
                </ul>
            </div>
            
            <p>In practice, computing eigenvalues directly can be cumbersome. For a $2 \times 2$ matrix, we can use a simpler test based on the determinant. Define:</p>
            
            <div class="formula">
                $$D = \det(H) = f_{xx}(a,b)f_{yy}(a,b) - [f_{xy}(a,b)]^2$$
            </div>

            <p>Then we have the <span class="topic-highlight">Second Derivative Test</span>:</p>
            
            <div class="formula">
                <ul style="list-style-type: none; padding-left: 0;">
                    <li>If $D > 0$ and $f_{xx}(a,b) > 0$, then $(a,b)$ is a local minimum.</li>
                    <li>If $D > 0$ and $f_{xx}(a,b) < 0$, then $(a,b)$ is a local maximum.</li>
                    <li>If $D < 0$, then $(a,b)$ is a saddle point.</li>
                    <li>If $D = 0$, the test is inconclusive (higher-order derivatives needed).</li>
                </ul>
            </div>

            <p>The intuition behind this test becomes clearer when we consider the quadratic approximation. Near a critical point, the function behaves like a paraboloid. The determinant test tells us about the shape of this paraboloid:</p>
            
            <div class="figure">
                <img src="https://via.placeholder.com/500x300" alt="Types of Critical Points">
                <div class="figure-caption">Figure 9.1: Illustrations of a local minimum, local maximum, and saddle point of a function of two variables.</div>
            </div>

            <div class="example-title">Example 9.1</div>
            <div class="formula" style="background-color: #f0f7ff; border-left-color: #3498db;">
                <p><strong>Question:</strong> Classify the critical points of the function $f(x,y) = 3x^2y - y^3 - 3x^2$.</p>
                
                <p><strong>Solution:</strong></p>
                <p>We first find the critical points by setting the gradient to zero:</p>
                
                $$\frac{\partial f}{\partial x} = 6xy - 6x = 6x(y - 1) = 0$$
                $$\frac{\partial f}{\partial y} = 3x^2 - 3y^2 = 3(x^2 - y^2) = 0$$
                
                <p>From the first equation, either $x = 0$ or $y = 1$. Let's examine each case:</p>
                
                <p>If $x = 0$, then the second equation gives us $-3y^2 = 0$, so $y = 0$. Thus $(0,0)$ is a critical point.</p>
                
                <p>If $y = 1$, then the second equation gives us $3(x^2 - 1) = 0$, so $x = \pm 1$. This yields two more critical points: $(1,1)$ and $(-1,1)$.</p>
                
                <p>Now, let's compute the second partial derivatives:</p>
                
                $$f_{xx} = 6y - 6 = 6(y - 1)$$
                $$f_{xy} = f_{yx} = 6x$$
                $$f_{yy} = -6y$$
                
                <p>For the critical point $(0,0)$:</p>
                
                $$f_{xx}(0,0) = 6(0 - 1) = -6$$
                $$f_{xy}(0,0) = 6 \cdot 0 = 0$$
                $$f_{yy}(0,0) = -6 \cdot 0 = 0$$
                
                <p>The determinant is $D = f_{xx}f_{yy} - (f_{xy})^2 = (-6) \cdot 0 - 0^2 = 0$.</p>
                
                <p>Since $D = 0$, the second derivative test is inconclusive. We'd need to examine higher-order terms or use other methods.</p>
                
                <p>For the critical point $(1,1)$:</p>
                
                $$f_{xx}(1,1) = 6(1 - 1) = 0$$
                $$f_{xy}(1,1) = 6 \cdot 1 = 6$$
                $$f_{yy}(1,1) = -6 \cdot 1 = -6$$
                
                <p>The determinant is $D = f_{xx}f_{yy} - (f_{xy})^2 = 0 \cdot (-6) - 6^2 = -36 < 0$.</p>
                
                <p>Since $D < 0$, $(1,1)$ is a saddle point.</p>
                
                <p>For the critical point $(-1,1)$:</p>
                
                $$f_{xx}(-1,1) = 6(1 - 1) = 0$$
                $$f_{xy}(-1,1) = 6 \cdot (-1) = -6$$
                $$f_{yy}(-1,1) = -6 \cdot 1 = -6$$
                
                <p>The determinant is $D = f_{xx}f_{yy} - (f_{xy})^2 = 0 \cdot (-6) - (-6)^2 = -36 < 0$.</p>
                
                <p>Since $D < 0$, $(-1,1)$ is also a saddle point.</p>
            </div>

            <div class="example-title">Example 9.2</div>
            <div class="formula" style="background-color: #f0f7ff; border-left-color: #3498db;">
                <p><strong>Question:</strong> Classify the critical points of the function $f(x,y) = x^2 + y^2 - 4xy + 6x - 2y$.</p>
                
                <p><strong>Solution:</strong></p>
                <p>We find the critical points by setting the gradient to zero:</p>
                
                $$\frac{\partial f}{\partial x} = 2x - 4y + 6 = 0$$
                $$\frac{\partial f}{\partial y} = 2y - 4x - 2 = 0$$
                
                <p>From the second equation, we get $y = 2x + 1$. Substituting into the first equation:</p>
                
                $$2x - 4(2x + 1) + 6 = 0$$
                $$2x - 8x - 4 + 6 = 0$$
                $$-6x + 2 = 0$$
                $$x = \frac{1}{3}$$
                
                <p>So $y = 2 \cdot \frac{1}{3} + 1 = \frac{5}{3}$. Thus $(\frac{1}{3}, \frac{5}{3})$ is our only critical point.</p>
                
                <p>Now we compute the second partial derivatives:</p>
                
                $$f_{xx} = 2$$
                $$f_{xy} = f_{yx} = -4$$
                $$f_{yy} = 2$$
                
                <p>The determinant is $D = f_{xx}f_{yy} - (f_{xy})^2 = 2 \cdot 2 - (-4)^2 = 4 - 16 = -12 < 0$.</p>
                
                <p>Since $D < 0$, the critical point $(\frac{1}{3}, \frac{5}{3})$ is a saddle point.</p>
            </div>

            <p>The Taylor expansion approach extends to functions of more than two variables, but the analysis becomes more complex. For a function $f(\mathbf{x})$ of $n$ variables, the Hessian is an $n \times n$ matrix, and we would need to examine the signs of all its eigenvalues or use matrix determinant techniques.</p>


            <p>The <span class="topic-highlight">Taylor expansion</span> and <span class="topic-highlight">second derivative test</span> are fundamental tools in optimization problems across engineering disciplines. They allow us to identify extrema of multivariable functions systematically, which is crucial for finding optimal designs, minimizing costs, or maximizing efficiency in various applications.</p>
            
            <div class="figure" style="background-color: #eefaf8; border-left: 4px solid #2ecc71; text-align: left;">
                <h3 style="margin-top: 0;">Key Insights about Classification of Critical Points</h3>
                <ul style="padding-left: 20px;">
                    <li>At a critical point, the function's behavior is primarily determined by its second-order terms.</li>
                    <li>The Hessian matrix encapsulates all second-order information about the function at a point.</li>
                    <li>The second derivative test provides a systematic way to classify critical points without computing eigenvalues directly.</li>
                    <li>For functions of many variables, examining the eigenvalues of the Hessian matrix is the general approach.</li>
                    <li>In degenerate cases where the determinant is zero, higher-order terms in the Taylor expansion become necessary.</li>
                </ul>
            </div>
        </section>

        <section id="supplementary-material" class="content-section">
            <div class="section-title">Supplementary Material: Additional Topics and Open Problems</div>
            <div class="lecture-title">Advanced Topics in Spin Glass Theory</div>
            <div class="author-info">Additional Notes</div>

            <div class="overview">
                <p><strong>Overview:</strong> This supplementary material covers additional topics in spin glass theory that, while important, were not covered in detail in the main lectures. We also discuss some open problems and current research directions in the field.</p>
            </div>

            <h4>Additional Topics</h4>

            <h5>1. Finite-Dimensional Spin Glasses</h5>
            <p>The behavior of spin glasses in finite dimensions remains challenging:</p>
            <ul>
                <li><strong>Edwards-Anderson model:</strong> Spins on a lattice $\mathbb{Z}^d$ with nearest-neighbor interactions</li>
                <li><strong>Lower critical dimension:</strong> Below which dimension is there no spin glass phase?</li>
                <li><strong>Nature of the phase transition:</strong> Continuous vs. first-order?</li>
                <li><strong>Structure of pure states:</strong> Is there RSB in finite dimensions?</li>
            </ul>

            <h5>2. Dynamics and Aging</h5>
            <p>Non-equilibrium behavior includes:</p>
            <ul>
                <li><strong>Aging:</strong> Correlation functions depend on both times</li>
                <li><strong>Domain growth:</strong> Very slow compared to ferromagnets</li>
                <li><strong>Memory and rejuvenation:</strong> Complex response to temperature changes</li>
                <li><strong>Violation of fluctuation-dissipation theorem</strong></li>
            </ul>

            <h5>3. Quantum Spin Glasses</h5>
            <p>Adding quantum effects:</p>
            <ul>
                <li><strong>Transverse field:</strong> Quantum tunneling between states</li>
                <li><strong>Quantum phase transitions:</strong> At $T=0$</li>
                <li><strong>Quantum annealing:</strong> Optimization algorithms</li>
                <li><strong>Many-body localization:</strong> Connection to disorder</li>
            </ul>

            <h4>Open Problems</h4>

            <h5>1. Mathematical Questions</h5>
            <ul>
                <li><strong>Ultrametricity:</strong> Rigorous proof in finite dimensions?</li>
                <li><strong>Chaos in temperature:</strong> Full mathematical understanding</li>
                <li><strong>Dynamics:</strong> Proving aging scenarios</li>
                <li><strong>TAP solutions:</strong> Complete classification</li>
            </ul>

            <h5>2. Algorithmic Challenges</h5>
            <ul>
                <li><strong>Finding ground states:</strong> Efficient algorithms?</li>
                <li><strong>Message passing:</strong> Beyond tree-like graphs</li>
                <li><strong>Quantum algorithms:</strong> Advantage over classical?</li>
                <li><strong>Machine learning:</strong> New architectures from spin glasses?</li>
            </ul>

            <h5>3. Applications</h5>
            <p>Emerging areas include:</p>
            <ul>
                <li><strong>Deep learning:</strong> Understanding loss landscapes</li>
                <li><strong>Random matrices:</strong> Non-Gaussian universality</li>
                <li><strong>High-dimensional statistics:</strong> Phase transitions</li>
                <li><strong>Quantum information:</strong> Error correction</li>
            </ul>

            <h4>Current Research Directions</h4>

            <h5>1. Mixed p-spin Models</h5>
            <p>Generalizations of SK model:</p>
            <ul>
                <li>Multiple interaction terms of different orders</li>
                <li>Rich phase diagrams and dynamics</li>
                <li>Connection to deep neural networks</li>
            </ul>

            <h5>2. First-Order Transitions</h5>
            <p>Understanding discontinuous transitions:</p>
            <ul>
                <li>Random constraint satisfaction</li>
                <li>Community detection</li>
                <li>Error correction thresholds</li>
            </ul>

            <h5>3. Non-equilibrium Protocols</h5>
            <p>New dynamical phenomena:</p>
            <ul>
                <li>Cyclic temperature protocols</li>
                <li>Quantum quenches</li>
                <li>Driven systems</li>
            </ul>

            <h4>Resources for Further Study</h4>

            <h5>1. Classical References</h5>
            <ul>
                <li>Mézard, Parisi, Virasoro: "Spin Glass Theory and Beyond"</li>
                <li>Fischer, Hertz: "Spin Glasses"</li>
                <li>Talagrand: "Spin Glasses: A Challenge for Mathematicians"</li>
            </ul>

            <h5>2. Modern Reviews</h5>
            <ul>
                <li>Recent developments in finite dimensions</li>
                <li>Applications to random optimization</li>
                <li>Quantum aspects and computing</li>
            </ul>

            <h5>3. Open-Source Resources</h5>
            <ul>
                <li>Simulation codes and libraries</li>
                <li>Benchmark problems</li>
                <li>Data analysis tools</li>
            </ul>

            <p><strong>Final Remarks:</strong> The field of spin glasses continues to evolve, with new connections being discovered to various areas of physics, mathematics, and computer science. The mathematical structures first identified in spin glasses (like replica symmetry breaking) have proven to be fundamental concepts that appear in many complex systems.</p>
        </section>

        <div class="navigation">
            <a href="class8.html">← Previous: Class 8</a>
            <a href="../index.html">Home</a>
            <a href="class10.html">Next: Class 10 →</a>
        </div>
    </div>
</body>
</html>